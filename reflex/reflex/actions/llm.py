# reflex/actions/llm.py
from typing import Dict, Any, Callable
import os
from anthropic import AsyncAnthropic
from .base import ActionBase

@ActionBase.register('llm')
class LLMAction(ActionBase):
    """
    LLM ê¸°ë°˜ Action (Tool Calling)
    
    Config:
        type: "llm" (í•„ìˆ˜)
        api: "claude" (í˜„ìž¬ claudeë§Œ ì§€ì›)
        model: "claude-sonnet-4-20250514"
        prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        temperature: 0.0~1.0 (ê¸°ë³¸: 0.7)
    """
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        
        self.api = config.get('api', 'claude')
        self.model = config.get('model', 'claude-sonnet-4-20250514')
        self.prompt = config.get('prompt', '')
        self.temperature = config.get('temperature', 0.7)
        
        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.api == 'claude':
            api_key = os.environ.get('ANTHROPIC_API_KEY')
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY environment variable not set")
            self.client = AsyncAnthropic(api_key=api_key)
        else:
            raise ValueError(f"Unsupported API: {self.api}")
    
    async def execute(
        self, 
        event: Dict[str, Any], 
        state: Dict[str, Any],
        tools: Dict[str, Callable]
    ) -> Dict[str, Any]:
        """LLMì—ê²Œ íŒë‹¨ ë§¡ê¸°ê³  Tool Callingìœ¼ë¡œ ì‹¤í–‰"""
        try:
            # 1. Tool ìŠ¤íŽ™ ì¤€ë¹„
            tool_specs = self._prepare_tool_specs(tools)
            
            # 2. ì‚¬ìš©ìž ë©”ì‹œì§€ êµ¬ì„±
            user_message = self._build_user_message(event, state)
            
            print(f"\nðŸ¤– Calling LLM...")
            print(f"   Model: {self.model}")
            print(f"   Tools: {list(tools.keys())}")
            
            # 3. LLM í˜¸ì¶œ
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                temperature=self.temperature,
                system=self.prompt,
                messages=[{
                    "role": "user",
                    "content": user_message
                }],
                tools=tool_specs if tool_specs else None
            )
            
            # 4. Tool Calling ì²˜ë¦¬
            tool_results = []
            text_response = ""
            
            for block in response.content:
                if block.type == 'tool_use':
                    tool_name = block.name
                    tool_args = block.input
                    
                    print(f"   ðŸ”§ LLM calls: {tool_name}({tool_args})")
                    
                    if tool_name in tools:
                        try:
                            result = await tools[tool_name](**tool_args)
                            tool_results.append({
                                'tool': tool_name,
                                'args': tool_args,
                                'result': result
                            })
                            print(f"      âœ“ Result: {result}")
                        except Exception as e:
                            print(f"      âœ— Error: {e}")
                            tool_results.append({
                                'tool': tool_name,
                                'args': tool_args,
                                'error': str(e)
                            })
                    else:
                        print(f"      âš ï¸ Tool not available")
                
                elif block.type == 'text':
                    text_response = block.text
                    print(f"   ðŸ’¬ LLM: {text_response}")
            
            return {
                'success': True,
                'tool_calls': tool_results,
                'text': text_response,
                'raw_response': response
            }
            
        except Exception as e:
            print(f"   âŒ LLM execution error: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e)
            }
    
    def _prepare_tool_specs(self, tools: Dict[str, Callable]) -> list:
        """Toolì„ Anthropic API í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        specs = []
        
        for tool_name, tool_func in tools.items():
            # ê¸°ë³¸ ìŠ¤íŽ™
            doc = getattr(tool_func, '__doc__', f"Execute {tool_name}")
            
            spec = {
                "name": tool_name,
                "description": doc.strip() if doc else f"Execute {tool_name}",
                "input_schema": {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            }
            
            specs.append(spec)
        
        return specs
    
    def _build_user_message(self, event: Dict[str, Any], state: Dict[str, Any]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì‚¬ìš©ìž ë©”ì‹œì§€ êµ¬ì„±"""
        lines = ["Current situation:\n"]
        
        # ì´ë²¤íŠ¸ ì •ë³´
        lines.append(f"Event: {event}\n")
        
        # ìƒíƒœ ì •ë³´
        if state:
            lines.append("\nCurrent state:")
            for key, value in state.items():
                lines.append(f"  - {key}: {value}")
        
        lines.append("\n\nPlease decide what actions to take.")
        
        return '\n'.join(lines)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': 'llm',
            'api': self.api,
            'model': self.model,
            'prompt': self.prompt,
            'temperature': self.temperature
        }
    
    def __repr__(self):
        return f"LLMAction(api='{self.api}', model='{self.model}')"